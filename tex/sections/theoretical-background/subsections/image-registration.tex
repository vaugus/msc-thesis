As originally proposed by \citeonline{lowe1999object}, the SIFT is a feature extraction approach for object and scene recognition. First, the scale-space extrema are detected with a difference-of-Gaussian function, applied in order to identify the invariant scale and orientation keypoints. Each keypoint is selected based on measures of their stability, and one or more orientations are assigned to each keypoint location based on image gradient directions. Finally, a measurement of the local image gradients is performed for the particular scales and neighborhood of each keypoint, followed by a transformation of those into a proper representation.

The custom SIFT implementation described here was proposed by \citeonline{lowe2004distinctive}. The difference-of-Gaussian method for the detection of scale-space extrema is a convolution of an image $f(x,y)$ with the difference of two nearby scales of distance $k$, given by

\begin{equation}
\label{eqn:DoG}
D(x,y,\sigma) = \left(G(x,y,k \sigma) - G(x,y,\sigma)\right) f(x,y),
\end{equation}

\noindent where $D(x,y,\sigma)$ is the result of the convolution and $G(x,y,\sigma)$ stands for a Gaussian function described as

\begin{equation}
\label{eqn:gaussian_function}
G(x,y,\sigma) = \frac{1}{\sqrt{2 \pi \sigma}} e^{- \frac{x^{2} + y^{2}}{\sigma^{2}}}.
\end{equation}

The difference-of-Gaussians is constructed by convolving the image with several Gaussians separated by the multiplicative factor $k$, followed by a reduction of the scale-space by doubling $\sigma$ at each change of scale. Next, the local maxima and minima (extrema) are detected by checking the 8-neighborhood in the current image and 9-neighborhood in the image, in adjacent scales. Having computed the scale-space extrema, the keypoints are localized by fitting a 3D quadratic function of local sample points with the Taylor expansion

\begin{equation}
\label{eqn:taylor_DoG}
D(\mathbf{x}) = D + 
                \frac{\partial D^{T}}{\partial  \mathbf{x}}\mathbf{x} + \frac{1}{2}\mathbf{x^{T}}\frac{\partial^{2} D}{\partial \mathbf{x}^{2}}\mathbf{x},
\end{equation}

\noindent where the derivatives of the difference-of-Gaussians matrix $D$ is computed at the sample point and $\mathbf{x} = (x,y,\sigma)^{T}$ is the offset for such point. The extremum location is found with the derivative of $D$ with respect to $\mathbf{x}$ by setting it to zero. The value of $D$ at the extremum provides a way to include only stable and good contrast extrema. As well as the low contrast keypoint exclusion, it is necessary to eliminate keypoints which possess a large principal curvature across the edge direction and a small one in its perpendicular direction; this is achieved with a threshold based on the sum and product of the eigenvalues from the trace and determinant of a Hessian matrix computed at the location and scale of each keypoint.

The next step is to provide the orientation of each keypoint concerning local image properties. This yields invariance to image rotation and is done by computing the gradient magnitude and the orientation for each smoothed image sample, denoted by

\begin{equation}
m(x,y) = \sqrt{(L(x + 1, y) - L(x - 1, y))^{2} + (L(x, y + 1) - L(x, y - 1))^{2}}
\end{equation}

\begin{equation}
\theta(x,y) = \tan^{-1}
			\left(
			\frac{L(x, y + 1) - L(x, y - 1)}
				 {L(x + 1, y) - L(x - 1, y)}
			\right),
\end{equation}

\noindent where $m(x,y)$ is the gradient magnitude, $\theta(x,y)$ is the orientation and $L(x,y)$ is the smoothed image, i.e. the observed image convolved with a Gaussian kernel. The obtained information is sampled around each keypoint location at the selected scale and Gaussian blur level, in order to generate the descriptor representation. The samples are then weighted by a Gaussian window and accumulated into orientation histograms that represent $4 \times 4$ subregions. The descriptors are computed from a $16 \times 16$ subarray. Finally, the advantages of the custom implementation of SIFT are the invariance to image rotation and scale, robustness across a substantial range of distortions (affine, additive noise and illumination changes) and computational efficiency.

The RANSAC algorithm is a non-deterministic iterative method for fitting a mathematical model to experimental data and also an outlier detector. \cite{fischler1981random}. As for the image registration application in this work, it is used to identify corresponding landmark points in overlapping image tiles \cite{saalfeld2019computational}. Then, the recognized matching points in each image undergo the geometric consistency filtering process with the expected transformation model and the maximal expected error parameters; this last filtering process aims to verify whether all points support the same transformation model and yield the best matches concerning all points for each image of the dataset.